{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import task1 as t1 \n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_root_min = '/Users/huayuzhu/Desktop/exam/raw_data/minute'\n",
    "data_root = '/Users/huayuzhu/Desktop/exam/raw_data/daily'\n",
    "output_dir = '/Users/huayuzhu/Desktop/exam/'\n",
    "def get_min_data_from_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file into a DataFrame, with the first column as row indices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        The file path of the CSV file to be read.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Transposed DataFrame with datetime as index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path, index_col=0) \n",
    "        data.index = pd.to_datetime(data.index)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return data\n",
    "def get_data_from_csv(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file into a DataFrame, with the first column as row indices, \n",
    "    transposes the result, and converts the row indices to datetime.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        The file path of the CSV file to be read.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Transposed DataFrame with datetime as index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path, index_col=0).T\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    return data\n",
    "amount = get_min_data_from_csv(f'{data_root_min}/amount.csv')\n",
    "volume = get_min_data_from_csv(f'{data_root_min}/volume.csv')\n",
    "close  = get_min_data_from_csv(f'{data_root_min}/close.csv')\n",
    "open  = get_min_data_from_csv(f'{data_root_min}/open.csv')\n",
    "\n",
    "S_DQ_RET = get_data_from_csv(f'{data_root}/S_DQ_RET.csv')\n",
    "S_905_DQ_RET =  get_data_from_csv(f'{data_root}/905S_DQ_RET.csv')\n",
    "S_DQ_MV = get_data_from_csv(f'{data_root}/S_DQ_MV.csv')\n",
    "S_RESTRICT = get_data_from_csv(f'{data_root}/S_RESTRICT.csv')\n",
    "S_DQ_OPEN = get_data_from_csv(f'{data_root}/S_DQ_OPEN.csv')\n",
    "S_DQ_ADJ_FACTOR = get_data_from_csv(f'{data_root}/S_DQ_ADJFACTOR.csv')\n",
    "S_DQ_CLOSE = get_data_from_csv(f'{data_root}/S_DQ_CLOSE.csv')\n",
    "S_DQ_VOLUME = get_data_from_csv(f'{data_root}/S_DQ_VOLUME.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_DQ_ADJ_FACTOR = S_DQ_ADJ_FACTOR/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_ADJ_CLOSE = S_DQ_CLOSE * S_DQ_ADJ_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_ADJ_OPEN = S_DQ_OPEN * S_DQ_ADJ_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_factor(df_adj_close, df_adj_open, df_volume, df_market_value, N):\n",
    "    \"\"\"\n",
    "    Calculates the mean overnight return for the days where the past N days' turnover rates\n",
    "    are in the top and bottom 20%.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_adj_close : DataFrame\n",
    "        Adjusted closing prices with dates as index and tickers as columns.\n",
    "    df_adj_open : DataFrame\n",
    "        Adjusted opening prices with dates as index and tickers as columns.\n",
    "    df_volume : DataFrame\n",
    "        Trading volume with dates as index and tickers as columns.\n",
    "    df_market_value : DataFrame\n",
    "        Market value with dates as index and tickers as columns.\n",
    "    N : int\n",
    "        The number of days to look back for turnover rates.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with the calculated mean overnight returns.\n",
    "    \"\"\"\n",
    "    overnight_returns = df_adj_open / df_adj_close.shift(1) - 1\n",
    "    turnover_rates = df_volume / df_market_value\n",
    "    \n",
    "    df = pd.concat([overnight_returns,turnover_rates], keys = ['OverNight','TurnOver'],axis = 1)\n",
    "    def calc_within_window(window_df):\n",
    "        turnover_window = window_df.loc[:, 'TurnOver']\n",
    "        overnight_window = window_df.loc[:, 'OverNight']\n",
    "        ranked_turnover = turnover_window.rank(pct=True)\n",
    "        is_top_20 = ranked_turnover >= 0.8\n",
    "        is_bottom_20 = ranked_turnover <= 0.2\n",
    "        mean_over_night = overnight_window[is_top_20 | is_bottom_20].mean()\n",
    "        \n",
    "        return mean_over_night\n",
    "    df_factor = pd.DataFrame(index = df.index[20:], columns = overnight_returns.columns)\n",
    "    # this is not applied for the large dataset, but due to time limit, I used for loop here for simplicity \n",
    "    for i in range(len(df_factor)-1): \n",
    "        df_factor.iloc[i] = calc_within_window(df[i:20+i])\n",
    "    return df_factor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_values = calculate_factor(S_ADJ_CLOSE, S_ADJ_OPEN,S_DQ_VOLUME , S_DQ_MV, N=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>873593</th>\n",
       "      <th>873665</th>\n",
       "      <th>873679</th>\n",
       "      <th>873690</th>\n",
       "      <th>873693</th>\n",
       "      <th>873703</th>\n",
       "      <th>873726</th>\n",
       "      <th>873749</th>\n",
       "      <th>873806</th>\n",
       "      <th>873833</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>97.433688</td>\n",
       "      <td>97.559973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.910844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.280437</td>\n",
       "      <td>98.671057</td>\n",
       "      <td>99.5095</td>\n",
       "      <td>99.534661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-03</th>\n",
       "      <td>97.220458</td>\n",
       "      <td>97.694433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.774616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.245672</td>\n",
       "      <td>98.671057</td>\n",
       "      <td>99.5095</td>\n",
       "      <td>99.441482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04</th>\n",
       "      <td>97.650309</td>\n",
       "      <td>97.694433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.796041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.371221</td>\n",
       "      <td>98.686205</td>\n",
       "      <td>99.693501</td>\n",
       "      <td>99.580154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-05</th>\n",
       "      <td>97.666331</td>\n",
       "      <td>97.694433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.949448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.405889</td>\n",
       "      <td>98.686205</td>\n",
       "      <td>99.693501</td>\n",
       "      <td>98.740599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>98.29922</td>\n",
       "      <td>98.232129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.844627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.405889</td>\n",
       "      <td>98.678285</td>\n",
       "      <td>99.693501</td>\n",
       "      <td>98.740599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>99.759484</td>\n",
       "      <td>99.477524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.252325</td>\n",
       "      <td>99.258936</td>\n",
       "      <td>101.014385</td>\n",
       "      <td>99.014257</td>\n",
       "      <td>99.228328</td>\n",
       "      <td>98.758149</td>\n",
       "      <td>99.142896</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>99.84363</td>\n",
       "      <td>99.769678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.263864</td>\n",
       "      <td>99.258936</td>\n",
       "      <td>101.108637</td>\n",
       "      <td>99.014257</td>\n",
       "      <td>99.275409</td>\n",
       "      <td>98.842166</td>\n",
       "      <td>99.371442</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>99.54827</td>\n",
       "      <td>99.110717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.056008</td>\n",
       "      <td>99.258936</td>\n",
       "      <td>101.108637</td>\n",
       "      <td>99.026579</td>\n",
       "      <td>99.089453</td>\n",
       "      <td>98.842166</td>\n",
       "      <td>99.224857</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>99.561745</td>\n",
       "      <td>98.951162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.029306</td>\n",
       "      <td>99.258936</td>\n",
       "      <td>100.384743</td>\n",
       "      <td>99.073105</td>\n",
       "      <td>99.089453</td>\n",
       "      <td>98.805486</td>\n",
       "      <td>99.371317</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1927 rows × 5566 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               1          2      3          4          5           6       \\\n",
       "2015-02-02  97.433688  97.559973    NaN  98.910844        NaN   98.280437   \n",
       "2015-02-03  97.220458  97.694433    NaN  98.774616        NaN   98.245672   \n",
       "2015-02-04  97.650309  97.694433    NaN  98.796041        NaN   98.371221   \n",
       "2015-02-05  97.666331  97.694433    NaN  98.949448        NaN   98.405889   \n",
       "2015-02-06   98.29922  98.232129    NaN  98.844627        NaN   98.405889   \n",
       "...               ...        ...    ...        ...        ...         ...   \n",
       "2022-12-26  99.759484  99.477524    NaN  99.252325  99.258936  101.014385   \n",
       "2022-12-27   99.84363  99.769678    NaN  99.263864  99.258936  101.108637   \n",
       "2022-12-28   99.54827  99.110717    NaN  99.056008  99.258936  101.108637   \n",
       "2022-12-29  99.561745  98.951162    NaN  99.029306  99.258936  100.384743   \n",
       "2022-12-30        NaN        NaN    NaN        NaN        NaN         NaN   \n",
       "\n",
       "               7          8          9          10      ... 873593 873665  \\\n",
       "2015-02-02  98.671057    99.5095  99.534661        NaN  ...    NaN    NaN   \n",
       "2015-02-03  98.671057    99.5095  99.441482        NaN  ...    NaN    NaN   \n",
       "2015-02-04  98.686205  99.693501  99.580154        NaN  ...    NaN    NaN   \n",
       "2015-02-05  98.686205  99.693501  98.740599        NaN  ...    NaN    NaN   \n",
       "2015-02-06  98.678285  99.693501  98.740599        NaN  ...    NaN    NaN   \n",
       "...               ...        ...        ...        ...  ...    ...    ...   \n",
       "2022-12-26  99.014257  99.228328  98.758149  99.142896  ...    NaN    NaN   \n",
       "2022-12-27  99.014257  99.275409  98.842166  99.371442  ...    NaN    NaN   \n",
       "2022-12-28  99.026579  99.089453  98.842166  99.224857  ...    NaN    NaN   \n",
       "2022-12-29  99.073105  99.089453  98.805486  99.371317  ...    NaN    NaN   \n",
       "2022-12-30        NaN        NaN        NaN        NaN  ...    NaN    NaN   \n",
       "\n",
       "           873679 873690 873693 873703 873726 873749 873806 873833  \n",
       "2015-02-02    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2015-02-03    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2015-02-04    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2015-02-05    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2015-02-06    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "2022-12-26    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2022-12-27    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2022-12-28    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2022-12-29    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2022-12-30    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[1927 rows x 5566 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>873593</th>\n",
       "      <th>873665</th>\n",
       "      <th>873679</th>\n",
       "      <th>873690</th>\n",
       "      <th>873693</th>\n",
       "      <th>873703</th>\n",
       "      <th>873726</th>\n",
       "      <th>873749</th>\n",
       "      <th>873806</th>\n",
       "      <th>873833</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>97.433688</td>\n",
       "      <td>97.559973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.910844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.280437</td>\n",
       "      <td>98.671057</td>\n",
       "      <td>99.5095</td>\n",
       "      <td>99.534661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-03</th>\n",
       "      <td>97.220458</td>\n",
       "      <td>97.694433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.774616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.245672</td>\n",
       "      <td>98.671057</td>\n",
       "      <td>99.5095</td>\n",
       "      <td>99.441482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04</th>\n",
       "      <td>97.650309</td>\n",
       "      <td>97.694433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.796041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.371221</td>\n",
       "      <td>98.686205</td>\n",
       "      <td>99.693501</td>\n",
       "      <td>99.580154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-05</th>\n",
       "      <td>97.666331</td>\n",
       "      <td>97.694433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.949448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.405889</td>\n",
       "      <td>98.686205</td>\n",
       "      <td>99.693501</td>\n",
       "      <td>98.740599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>98.29922</td>\n",
       "      <td>98.232129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.844627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.405889</td>\n",
       "      <td>98.678285</td>\n",
       "      <td>99.693501</td>\n",
       "      <td>98.740599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>99.759484</td>\n",
       "      <td>99.477524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.252325</td>\n",
       "      <td>99.258936</td>\n",
       "      <td>101.014385</td>\n",
       "      <td>99.014257</td>\n",
       "      <td>99.228328</td>\n",
       "      <td>98.758149</td>\n",
       "      <td>99.142896</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>99.84363</td>\n",
       "      <td>99.769678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.263864</td>\n",
       "      <td>99.258936</td>\n",
       "      <td>101.108637</td>\n",
       "      <td>99.014257</td>\n",
       "      <td>99.275409</td>\n",
       "      <td>98.842166</td>\n",
       "      <td>99.371442</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>99.54827</td>\n",
       "      <td>99.110717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.056008</td>\n",
       "      <td>99.258936</td>\n",
       "      <td>101.108637</td>\n",
       "      <td>99.026579</td>\n",
       "      <td>99.089453</td>\n",
       "      <td>98.842166</td>\n",
       "      <td>99.224857</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>99.561745</td>\n",
       "      <td>98.951162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.029306</td>\n",
       "      <td>99.258936</td>\n",
       "      <td>100.384743</td>\n",
       "      <td>99.073105</td>\n",
       "      <td>99.089453</td>\n",
       "      <td>98.805486</td>\n",
       "      <td>99.371317</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1927 rows × 5566 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               1          2      3          4          5           6       \\\n",
       "2015-02-02  97.433688  97.559973    NaN  98.910844        NaN   98.280437   \n",
       "2015-02-03  97.220458  97.694433    NaN  98.774616        NaN   98.245672   \n",
       "2015-02-04  97.650309  97.694433    NaN  98.796041        NaN   98.371221   \n",
       "2015-02-05  97.666331  97.694433    NaN  98.949448        NaN   98.405889   \n",
       "2015-02-06   98.29922  98.232129    NaN  98.844627        NaN   98.405889   \n",
       "...               ...        ...    ...        ...        ...         ...   \n",
       "2022-12-26  99.759484  99.477524    NaN  99.252325  99.258936  101.014385   \n",
       "2022-12-27   99.84363  99.769678    NaN  99.263864  99.258936  101.108637   \n",
       "2022-12-28   99.54827  99.110717    NaN  99.056008  99.258936  101.108637   \n",
       "2022-12-29  99.561745  98.951162    NaN  99.029306  99.258936  100.384743   \n",
       "2022-12-30        NaN        NaN    NaN        NaN        NaN         NaN   \n",
       "\n",
       "               7          8          9          10      ... 873593 873665  \\\n",
       "2015-02-02  98.671057    99.5095  99.534661        NaN  ...    NaN    NaN   \n",
       "2015-02-03  98.671057    99.5095  99.441482        NaN  ...    NaN    NaN   \n",
       "2015-02-04  98.686205  99.693501  99.580154        NaN  ...    NaN    NaN   \n",
       "2015-02-05  98.686205  99.693501  98.740599        NaN  ...    NaN    NaN   \n",
       "2015-02-06  98.678285  99.693501  98.740599        NaN  ...    NaN    NaN   \n",
       "...               ...        ...        ...        ...  ...    ...    ...   \n",
       "2022-12-26  99.014257  99.228328  98.758149  99.142896  ...    NaN    NaN   \n",
       "2022-12-27  99.014257  99.275409  98.842166  99.371442  ...    NaN    NaN   \n",
       "2022-12-28  99.026579  99.089453  98.842166  99.224857  ...    NaN    NaN   \n",
       "2022-12-29  99.073105  99.089453  98.805486  99.371317  ...    NaN    NaN   \n",
       "2022-12-30        NaN        NaN        NaN        NaN  ...    NaN    NaN   \n",
       "\n",
       "           873679 873690 873693 873703 873726 873749 873806 873833  \n",
       "2015-02-02    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2015-02-03    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2015-02-04    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2015-02-05    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2015-02-06    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "2022-12-26    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2022-12-27    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2022-12-28    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2022-12-29    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2022-12-30    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[1927 rows x 5566 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Lengths must match to compare",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[204], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test1 \u001b[38;5;241m=\u001b[39m t1\u001b[38;5;241m.\u001b[39mTestInfo()\n\u001b[1;32m      2\u001b[0m factor1 \u001b[38;5;241m=\u001b[39m t1\u001b[38;5;241m.\u001b[39mOneFactorTest(factor_values)\n\u001b[0;32m----> 3\u001b[0m factor1\u001b[38;5;241m.\u001b[39mcompare_with_benchmark(test1,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFactor1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/t1derivative/task1.py:229\u001b[0m, in \u001b[0;36mOneFactorTest.compare_with_benchmark\u001b[0;34m(self, test_info, name, output)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_with_benchmark\u001b[39m(\u001b[38;5;28mself\u001b[39m,test_info,name,output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 229\u001b[0m     per_top, per_bottom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrade(test_info)\n\u001b[1;32m    230\u001b[0m     ret_top \u001b[38;5;241m=\u001b[39m per_top\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_return\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m    231\u001b[0m     ret_bottom \u001b[38;5;241m=\u001b[39m per_bottom\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_return\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m~/Desktop/t1derivative/task1.py:150\u001b[0m, in \u001b[0;36mOneFactorTest.trade\u001b[0;34m(self, test_info)\u001b[0m\n\u001b[1;32m    147\u001b[0m top_r \u001b[38;5;241m=\u001b[39m factor_resample\u001b[38;5;241m.\u001b[39mcopy() \n\u001b[1;32m    148\u001b[0m bottom_r \u001b[38;5;241m=\u001b[39m factor_resample\u001b[38;5;241m.\u001b[39mcopy() \n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (factor_resample\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m!=\u001b[39m price_resample\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease debug\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (date, signals) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(factor_resample\u001b[38;5;241m.\u001b[39miterrows()):\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# here equal weighted portfolio strategy is used, Markovitz, or CAPM optimization may give better result  \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:44\u001b[0m, in \u001b[0;36mOpsMixin.__ne__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ne__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ne__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39mne)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:7113\u001b[0m, in \u001b[0;36mIndex._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7108\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[1;32m   7110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, (np\u001b[38;5;241m.\u001b[39mndarray, Index, ABCSeries, ExtensionArray)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m   7111\u001b[0m     \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   7112\u001b[0m ) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(other):\n\u001b[0;32m-> 7113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCMultiIndex):\n\u001b[1;32m   7116\u001b[0m     other \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Lengths must match to compare"
     ]
    }
   ],
   "source": [
    "test1 = t1.TestInfo()\n",
    "factor1 = t1.OneFactorTest(factor_values)\n",
    "factor1.compare_with_benchmark(test1,'Factor1',False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestInfo: \n",
    "    def __init__(self, group_number = 10, trading_frequency = 'W', initial_capital = None, trading_cost =0.0):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - group_number(int): Number of groups to divide into (default 10 for deciles).\n",
    "        - trading_frequency(str): \"M\" (monthly), \"W\" (weekly) (default to weekly)\n",
    "        - initial_capital(float): initial capital plan to invest, default to the capital needed at first period trading \n",
    "        - trading cost(float): trading cost percentage, default to 0 \n",
    "\n",
    "        \"\"\"\n",
    "        self.group_number = group_number \n",
    "        self.trading_frequency = trading_frequency\n",
    "        self.initial_capital = initial_capital \n",
    "        self.trading_cost = trading_cost \n",
    "\n",
    "class OneFactorTest: \n",
    "    \"\"\"\n",
    "    A class to conduct single factor testing for stock trading strategies. It ranks stocks, handles trade intervals,\n",
    "    executes trades, and evaluates performance metrics against a benchmark.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    factor : DataFrame\n",
    "        Factor data used to rank stocks.\n",
    "    stock_price_open : DataFrame\n",
    "        Stock opening prices.\n",
    "    restricted_stock_df : DataFrame\n",
    "        Information on stocks that are restricted from trading.\n",
    "    benchmark : DataFrame\n",
    "        Benchmark data for comparison.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    rank_stock(test_info):\n",
    "        Ranks stocks based on the provided factor values.\n",
    "\n",
    "    trade_interval(df, test_info):\n",
    "        Resamples the given dataframe to the specified trading frequency and forward fills missing data.\n",
    "\n",
    "    trade(test_info):\n",
    "        Executes trades based on stock rankings and calculates performance.\n",
    "\n",
    "    evaluation_metrics(performance, adj1=48, var=0.05):\n",
    "        Calculates various performance metrics like attribution analysis and risk analysis metrics.\n",
    "\n",
    "    eval_combined(test_info):\n",
    "        Evaluates and combines performance metrics for top and bottom ranked stocks.\n",
    "\n",
    "    compare_with_benchmark(test_info, name, output=False):\n",
    "        Compares the strategy's performance with a benchmark, returns a dataframe of excess returns.\n",
    "\n",
    "    plot_comparison_with_benchmark(test_info, name):\n",
    "        Generates a plot comparing the daily and cumulative excess returns against a benchmark.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,test_factor):\n",
    "        min_date = max(test_factor.index.min(), S_DQ_OPEN.index.min())\n",
    "        max_date = min(test_factor.index.max(), S_DQ_OPEN.index.max())\n",
    "\n",
    "        self.factor = test_factor.loc[min_date:max_date]\n",
    "        self.stock_price_open = S_DQ_OPEN.loc[min_date:max_date]\n",
    "        self.restricted_stock_df = S_RESTRICT\n",
    "        self.benchmark = S_905_DQ_RET.loc[min_date:max_date]\n",
    "    \n",
    "    def rank_stock(self,test_info): \n",
    "        factor_value = self.factor.copy()\n",
    "        percentile = factor_value.rank(axis=1, pct=True)\n",
    "        group_number = test_info.group_number - ((1 - percentile) * test_info.group_number) // 1\n",
    "        return group_number\n",
    "    \n",
    "    def trade_interval(self,df,test_info):\n",
    "        df_factor = df.resample(test_info.trading_frequency).first()   \n",
    "        df_factor = df_factor.ffill() \n",
    "        return df_factor\n",
    "\n",
    "    def trade(self,test_info): \n",
    "        df = self.rank_stock(test_info)\n",
    "        df_price = self.stock_price_open\n",
    "\n",
    "        # decide initial capital to trade \n",
    "        if test_info.initial_capital is not None: \n",
    "            initial_k = test_info.initial_capital\n",
    "        else:\n",
    "            p_1_top = df.iloc[0] == 1.0\n",
    "            p_1_bottom = df.iloc[0] == 10.0\n",
    "            p_1_top_capital = df_price.iloc[0][p_1_top].sum()\n",
    "            p_1_bottom_capital = df_price.iloc[0][p_1_bottom].sum()\n",
    "            initial_k = 1000 * (p_1_bottom_capital + p_1_top_capital)\n",
    "        side_k = initial_k / 2\n",
    "        top_pnl_tracker = {'total_pnl': [0], 'cumulative_pnl': [0]}\n",
    "        top_return_tracker = {'return': [0], 'net_return': [0]}\n",
    "        bottom_pnl_tracker = {'total_pnl': [0], 'cumulative_pnl': [0]}\n",
    "        bottom_return_tracker = {'net_return': [0]}\n",
    "        \n",
    "        factor_resample = self.trade_interval(df,test_info)\n",
    "        price_resample = self.trade_interval(df_price, test_info)\n",
    "        #min = np.max(factor_resample.index.min(),price_resample.index.min())\n",
    "        #max = np.min(factor_resample.index.max(),price_resample.index.max())\n",
    "        #factor_resample = factor_resample.loc[min:max]\n",
    "        #price_resample = price_resample.loc[min:max]\n",
    "\n",
    "\n",
    "        top_r = factor_resample.copy() \n",
    "        bottom_r = factor_resample.copy() \n",
    "        \n",
    "        if (factor_resample.index != price_resample.index).any():\n",
    "            print('please debug')\n",
    "        for i, (date, signals) in enumerate(factor_resample.iterrows()):\n",
    "            # here equal weighted portfolio strategy is used, Markovitz, or CAPM optimization may give better result  \n",
    "            top = signals == 1.0\n",
    "            bottom = signals == 10.0\n",
    "            top_k = price_resample.loc[date][top].sum()\n",
    "            bottom_k = price_resample.loc[date][bottom].sum()\n",
    "            top_ratio = side_k / top_k if top_k else 0\n",
    "            bottom_ratio = side_k / bottom_k if bottom_k else 0\n",
    "            top_r.loc[date] = signals.apply(lambda x: top_ratio if x == 1 else 0)\n",
    "            bottom_r.loc[date] = signals.apply(lambda x: bottom_ratio if x == 1 else 0)\n",
    "\n",
    "            # profit calculation \n",
    "            if i > 0: \n",
    "                price_change = price_resample.iloc[i] - price_resample.iloc[i-1]\n",
    "                \n",
    "                top_pnl = (top_r.iloc[i-1] * price_change).sum()\n",
    "                bottom_pnl = (bottom_r.iloc[i-1] * price_change).sum()\n",
    "        \n",
    "                top_cumulative_pnl = top_pnl_tracker['cumulative_pnl'][i-1] + top_pnl\n",
    "                bottom_cumulative_pnl = bottom_pnl_tracker['cumulative_pnl'][i-1] + bottom_pnl\n",
    "\n",
    "                top_pnl_tracker['total_pnl'].append(top_pnl)\n",
    "                top_pnl_tracker['cumulative_pnl'].append(top_cumulative_pnl)\n",
    "\n",
    "                bottom_pnl_tracker['total_pnl'].append(bottom_pnl)\n",
    "                bottom_pnl_tracker['cumulative_pnl'].append(bottom_cumulative_pnl)\n",
    "\n",
    "                top_return_tracker['net_return'].append(top_pnl/side_k - test_info.trading_cost)\n",
    "                bottom_return_tracker['net_return'].append(bottom_pnl/side_k - test_info.trading_cost)\n",
    "        df_top_pnl_tracker = pd.DataFrame(top_pnl_tracker, index=factor_resample.index)\n",
    "        df_top_return_tracker = pd.DataFrame(top_return_tracker, index=factor_resample.index)\n",
    "        df_top_performance = pd.concat([df_top_pnl_tracker, df_top_return_tracker], axis=1)\n",
    "        df_top_performance['cumulative_return'] = ((df_top_performance['net_return'] + 1).cumprod() -1)/100\n",
    "\n",
    "        df_bottom_pnl_tracker = pd.DataFrame(bottom_pnl_tracker, index=factor_resample.index)\n",
    "        df_bottom_return_tracker = pd.DataFrame(bottom_return_tracker, index=factor_resample.index)\n",
    "        df_bottom_performance = pd.concat([df_bottom_pnl_tracker, df_bottom_return_tracker], axis=1)\n",
    "        df_bottom_performance['cumulative_return'] = ((df_bottom_performance['net_return'] + 1).cumprod() -1)/100\n",
    "\n",
    "        return df_top_performance, df_bottom_performance\n",
    "    \n",
    "    def evaluation_mectrics(self,performance,adj1 = 48,var=0.05): \n",
    "        summary = dict()\n",
    "        data = performance.loc[:,['net_return']].dropna()\n",
    "        summary[\"Annualized Return\"] = data.mean() * adj1\n",
    "        summary[\"Annualized Volatility\"] = data.std() * np.sqrt(adj1)\n",
    "        summary[\"Annualized Sharpe Ratio\"] = (\n",
    "            summary[\"Annualized Return\"] / summary[\"Annualized Volatility\"]\n",
    "        )\n",
    "        summary[\"Annualized Sortino Ratio\"] = summary[\"Annualized Return\"] / (\n",
    "            data[data < 0].std() * np.sqrt(adj1)\n",
    "        )\n",
    "\n",
    "        summary[\"Skewness\"] = data.skew()\n",
    "        summary[\"Excess Kurtosis\"] = data.kurtosis()\n",
    "        summary[f\"VaR ({var})\"] = data.quantile(var, axis=0)\n",
    "        summary[f\"CVaR ({var})\"] = data[data <= data.quantile(var, axis=0)].mean()\n",
    "        summary[\"Min\"] = data.min()\n",
    "        summary[\"Max\"] = data.max()\n",
    "\n",
    "        wealth_index = 1000 * (1 + data).cumprod()\n",
    "        previous_peaks = wealth_index.cummax()\n",
    "        drawdowns = (wealth_index - previous_peaks) / previous_peaks\n",
    "\n",
    "        summary[\"Max Drawdown\"] = drawdowns.min()\n",
    "\n",
    "        summary[\"Bottom\"] = drawdowns.idxmin()\n",
    "        summary[\"Peak\"] = previous_peaks.idxmax()\n",
    "        return pd.DataFrame(summary) \n",
    "    \n",
    "    def eval_combined(self,test_info): \n",
    "        per_top, per_bottom = self.trade(test_info)\n",
    "        top = self.evaluation_mectrics('top',per_top,adj1 = 48,var=0.05)\n",
    "        bottom = self.evaluation_mectrics('bottom',per_bottom,adj1 = 48,var=0.05)\n",
    "        return pd.concat([top,bottom], axis=0,keys=['top', 'bottom'])\n",
    "    \n",
    "    def compare_with_benchmark(self,test_info,name,output = False):\n",
    "        per_top, per_bottom = self.trade(test_info)\n",
    "        ret_top = per_top.loc[:,['net_return']].dropna()\n",
    "        ret_bottom = per_bottom.loc[:,['net_return']].dropna()\n",
    " \n",
    "\n",
    "        daily_resampled_top = ret_top.resample('D').ffill().div(5)\n",
    "        daily_resampled_bottom = ret_bottom.resample('D').ffill().div(5)\n",
    "        daily_resampled_top = daily_resampled_top.reindex(self.benchmark.index, method='ffill')  \n",
    "        daily_resampled_bottom = daily_resampled_bottom.reindex(self.benchmark.index, method='ffill') \n",
    "\n",
    "        daily_resampled_bottom.fillna(0, inplace= True)\n",
    "        daily_resampled_top.fillna(0, inplace = True)\n",
    "\n",
    "        if (self.benchmark.index != daily_resampled_bottom.index).any(): \n",
    "            print('please debug')\n",
    "        summary = pd.DataFrame(index = self.benchmark.index) \n",
    "        summary[\"Daily excess_return TOP\"] = (daily_resampled_top['net_return'] - self.benchmark[905])\n",
    "        summary[\"Cumulative excess_return TOP\"] = (1 + summary['Daily excess_return TOP']).cumprod() - 1\n",
    "        summary[\"Daily excess_return BOTTOM\"] = (daily_resampled_top['net_return'] - self.benchmark[905])\n",
    "        summary[\"Cumulative excess_return BOTTOM\"] = (1 + summary['Daily excess_return BOTTOM']).cumprod() - 1\n",
    "\n",
    "        if output:\n",
    "            summary.to_csv(f'{output_dir}/{name}_compairson_ret.csv')\n",
    "\n",
    "        return summary\n",
    "    \n",
    "    def plot_comparison_with_benchmark(self, test_info,name):\n",
    "        df = self.compare_with_benchmark(test_info,name)\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df['Daily excess_return TOP'], name='Top Daily'),\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df['Daily excess_return BOTTOM'], name='Bottom Daily'),\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df['Cumulative excess_return TOP'], name='Top Cumulative'),\n",
    "            secondary_y=True,\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=df.index, y=df['Cumulative excess_return BOTTOM'], name='Bottom Cumulative'),\n",
    "            secondary_y=True,\n",
    "        )\n",
    "       \n",
    "        fig.update_layout(\n",
    "            title_text=name+\"Comparison of Daily and Cumulative Excess Returns\",\n",
    "            plot_bgcolor='white',  \n",
    "            xaxis_showgrid=False,  \n",
    "            yaxis_showgrid=False,  \n",
    "            yaxis2_showgrid=False,  \n",
    "            autosize=True,  \n",
    "            template='plotly_white',\n",
    "            colorway=px.colors.qualitative.Vivid\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Daily excess_return TOP</th>\n",
       "      <th>Cumulative excess_return TOP</th>\n",
       "      <th>Daily excess_return BOTTOM</th>\n",
       "      <th>Cumulative excess_return BOTTOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>-0.010589</td>\n",
       "      <td>-0.010589</td>\n",
       "      <td>-0.010589</td>\n",
       "      <td>-0.010589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-03</th>\n",
       "      <td>-0.016629</td>\n",
       "      <td>-0.027042</td>\n",
       "      <td>-0.016629</td>\n",
       "      <td>-0.027042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04</th>\n",
       "      <td>-0.003534</td>\n",
       "      <td>-0.030480</td>\n",
       "      <td>-0.003534</td>\n",
       "      <td>-0.030480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-05</th>\n",
       "      <td>0.017621</td>\n",
       "      <td>-0.013396</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>-0.013396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-06</th>\n",
       "      <td>0.020192</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>0.020192</td>\n",
       "      <td>0.006525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>-0.022332</td>\n",
       "      <td>-0.848989</td>\n",
       "      <td>-0.022332</td>\n",
       "      <td>-0.848989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>-0.008957</td>\n",
       "      <td>-0.850342</td>\n",
       "      <td>-0.008957</td>\n",
       "      <td>-0.850342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>-0.002613</td>\n",
       "      <td>-0.850733</td>\n",
       "      <td>-0.002613</td>\n",
       "      <td>-0.850733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>-0.012321</td>\n",
       "      <td>-0.852572</td>\n",
       "      <td>-0.012321</td>\n",
       "      <td>-0.852572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>-0.004623</td>\n",
       "      <td>-0.853254</td>\n",
       "      <td>-0.004623</td>\n",
       "      <td>-0.853254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1927 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Daily excess_return TOP  Cumulative excess_return TOP  \\\n",
       "2015-02-02                -0.010589                     -0.010589   \n",
       "2015-02-03                -0.016629                     -0.027042   \n",
       "2015-02-04                -0.003534                     -0.030480   \n",
       "2015-02-05                 0.017621                     -0.013396   \n",
       "2015-02-06                 0.020192                      0.006525   \n",
       "...                             ...                           ...   \n",
       "2022-12-26                -0.022332                     -0.848989   \n",
       "2022-12-27                -0.008957                     -0.850342   \n",
       "2022-12-28                -0.002613                     -0.850733   \n",
       "2022-12-29                -0.012321                     -0.852572   \n",
       "2022-12-30                -0.004623                     -0.853254   \n",
       "\n",
       "            Daily excess_return BOTTOM  Cumulative excess_return BOTTOM  \n",
       "2015-02-02                   -0.010589                        -0.010589  \n",
       "2015-02-03                   -0.016629                        -0.027042  \n",
       "2015-02-04                   -0.003534                        -0.030480  \n",
       "2015-02-05                    0.017621                        -0.013396  \n",
       "2015-02-06                    0.020192                         0.006525  \n",
       "...                                ...                              ...  \n",
       "2022-12-26                   -0.022332                        -0.848989  \n",
       "2022-12-27                   -0.008957                        -0.850342  \n",
       "2022-12-28                   -0.002613                        -0.850733  \n",
       "2022-12-29                   -0.012321                        -0.852572  \n",
       "2022-12-30                   -0.004623                        -0.853254  \n",
       "\n",
       "[1927 rows x 4 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = TestInfo()\n",
    "factor1 = OneFactorTest(factor_values)\n",
    "factor1.compare_with_benchmark(test1,'Factor1',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rankIC(factor, price_df, N): \n",
    "    ret = (price_df.shift(-N)/price_df - 1)[:-5]\n",
    "    factor = factor[:-5]\n",
    "    rankIC = pd.DataFrame(index=factor.resample('M').mean().index)\n",
    "\n",
    "    for ticker in factor.columns:\n",
    "        combined = pd.concat([factor[ticker], ret[ticker]], axis=1, keys=['factor', 'returns']) \n",
    "        combined.dropna(inplace=True)\n",
    "        if combined.empty:\n",
    "             rankIC[ticker] = pd.Series(pd.NA, index=rankIC.index) \n",
    "        else:\n",
    "            monthly_corr = combined.resample('M').apply(lambda x: x['factor'].corr(x['returns'], method='spearman'))\n",
    "            rankIC[ticker] = monthly_corr \n",
    "    return rankIC\n",
    "\n",
    "def calc_ICIR(factor, price_df, N):\n",
    "    rankIC = calc_rankIC(factor, price_df, N)\n",
    "    ICIR = rankIC.mean(axis = 0)/ rankIC.std(axis =0)\n",
    "    ICIR = ICIR.to_frame()\n",
    "    return ICIR.T \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>873593</th>\n",
       "      <th>873665</th>\n",
       "      <th>873679</th>\n",
       "      <th>873690</th>\n",
       "      <th>873693</th>\n",
       "      <th>873703</th>\n",
       "      <th>873726</th>\n",
       "      <th>873749</th>\n",
       "      <th>873806</th>\n",
       "      <th>873833</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.300946</td>\n",
       "      <td>-0.057467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.225103</td>\n",
       "      <td>-0.047986</td>\n",
       "      <td>-0.061878</td>\n",
       "      <td>-0.150308</td>\n",
       "      <td>-0.068883</td>\n",
       "      <td>-0.15833</td>\n",
       "      <td>-0.169956</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 5566 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1         2      3         4         5         6         7       \\\n",
       "0 -0.300946 -0.057467    NaN -0.225103 -0.047986 -0.061878 -0.150308   \n",
       "\n",
       "     8        9         10      ... 873593 873665 873679 873690 873693 873703  \\\n",
       "0 -0.068883 -0.15833 -0.169956  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "  873726 873749 873806 873833  \n",
       "0    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[1 rows x 5566 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_ICIR(factor_values.loc['2016':],S_DQ_OPEN.loc['2016':],5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
